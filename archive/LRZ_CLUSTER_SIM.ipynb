{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4p1LUoe8L/K9aCxhf7/HW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freethechicken/pbh_simulations/blob/main/LRZ_CLUSTER_SIM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0A5GTOdTVgD"
      },
      "outputs": [],
      "source": [
        "# @title Import packages\n",
        "\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from cupyx.scipy.special import erf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gc\n",
        "import os\n",
        "\n",
        "from scipy.special import erf\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from tqdm import tqdm\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1.11 GPU Random field simulations\n",
        "\n",
        "class GPU_RFSIM:\n",
        "\n",
        "    def __init__(self, mean, std_dev, pixel, z_pixel, amplitude, k_power, lamb, n_sigma):\n",
        "        self.mean = mean\n",
        "        self.std_dev = std_dev\n",
        "        self.pixel = pixel\n",
        "        self.z_pixel = z_pixel\n",
        "        self.amplitude = amplitude\n",
        "        self.k_power = k_power\n",
        "        self.lamb = lamb\n",
        "        self.n_sigma = n_sigma\n",
        "\n",
        "    def grf_64f(self):\n",
        "        # 3D Fast Fourier transform of the white noise\n",
        "        white_noise = cp.random.normal(self.mean, self.std_dev, (self.pixel, self.pixel, self.z_pixel))\n",
        "        #print(f\"white_noise allocates: {white_noise.nbytes / (1024**2):.2f} MB of memory.\")\n",
        "        #print(f\"Total memory usage: {self.get_process_memory():.2f} MB\")\n",
        "\n",
        "        fft_white_noise = cp.fft.fftn(white_noise)\n",
        "        del white_noise\n",
        "        #print(f\"fft_white_noise allocates: {fft_white_noise.nbytes / (1024**2):.2f} MB of memory.\")\n",
        "        #print(f\"Total memory usage: {self.get_process_memory():.2f} MB\")\n",
        "\n",
        "        # Generating FFT momentum\n",
        "        kx = cp.fft.fftfreq(self.pixel)*self.pixel\n",
        "        ky = cp.fft.fftfreq(self.pixel)*self.pixel\n",
        "        kz = cp.fft.fftfreq(self.z_pixel)*self.z_pixel\n",
        "\n",
        "        kx_grid, ky_grid, kz_grid = cp.meshgrid(kx, ky, kz, sparse = True)\n",
        "        del kx, ky, kz\n",
        "        # Genearting FFT momentum 3D array\n",
        "        # Norm of k\n",
        "\n",
        "        k_norm = cp.sqrt(kx_grid**2 + ky_grid**2  + kz_grid**2)\n",
        "        k_norm[0][0][0] = cp.inf  # Regularize divergence at k=0\n",
        "        del kx_grid, ky_grid, kz_grid\n",
        "        #print(f\"k_norm allocates: {k_norm.nbytes / (1024**2):.2f} MB of memory\")\n",
        "        #print(f\"Total memory usage: {self.get_process_memory():.2f} MB\")\n",
        "\n",
        "        # Power Spectrum P_k\n",
        "        power_spectrum = (self.amplitude*(((2*cp.pi/self.pixel)*k_norm)**(-1*self.k_power)))  # P(k)=amplitude/k^{power},\n",
        "        del k_norm\n",
        "        #print(f\"power_spectrum allocates: {power_spectrum.nbytes / (1024**2):.2f} MB of memory\")\n",
        "        #print(f\"Total memory usage: {self.get_process_memory():.2f} MB\")\n",
        "\n",
        "        # Multiply the power spectrum with the transformed white noise to get the realization of the spectrum\n",
        "        fourier_amplitudes_sqrt =  cp.sqrt(power_spectrum, out=power_spectrum)*fft_white_noise\n",
        "        del power_spectrum, fft_white_noise\n",
        "        #print(f\"fourier_amplitudes_sqrt allocates: {fourier_amplitudes_sqrt.nbytes / (1024**2):.2f} MB of memory\")\n",
        "        #print(f\"Total memory usage: {self.get_process_memory():.2f} MB\")\n",
        "\n",
        "        # Perform inverse Fourier transform to obtain the Gaussian random field in the spatial domain\n",
        "        gaussian_random_field = cp.fft.ifftn(fourier_amplitudes_sqrt).real\n",
        "        del fourier_amplitudes_sqrt\n",
        "        gc.collect()\n",
        "        #print(f\"gaussian_random_field allocates: {gaussian_random_field.nbytes / (1024**2):.2f} MB of memory\")\n",
        "\n",
        "        # Final estimation of memory usage\n",
        "        #print(f\"Total memory usage: {self.get_process_memory():.2f} MB\")\n",
        "\n",
        "        return gaussian_random_field\n",
        "\n",
        "\n",
        "    def gaussian_to_exp(self, grf):\n",
        "        grf_mean = cp.mean(grf)\n",
        "        grf_std_dev = cp.std(grf)\n",
        "        xu = 0.5 * (1 + erf((grf - grf_mean) / (cp.sqrt(2) * grf_std_dev)))\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        exprf = -1/self.lamb  * cp.log(1 - xu)\n",
        "\n",
        "        return exprf\n",
        "#        return gaussian_random_field\n",
        "\n",
        "    def statistic_overview(self, exprf):\n",
        "\n",
        "        all_points = cp.asnumpy(exprf.flatten())\n",
        "        exprf_std = np.std(all_points)\n",
        "        exprf_mean = np.mean(all_points)\n",
        "        cutoff = exprf_mean + self.n_sigma*exprf_std\n",
        "\n",
        "        plt.style.use('seaborn-darkgrid')\n",
        "        #print(f'Standard deviation = {exprf_std_3d:.2f}')\n",
        "        #print(f'Mean = {exprf_mean_3d:.2f}')\n",
        "        #print(f'Cutoff = {cutoff_3d:.2f}, i.e. {n_sigma} Sigmas from the mean at {exprf_mean_3d:.2f}')\n",
        "\n",
        "        # Create a figure object\n",
        "        fig, ax = plt.subplots()\n",
        "\n",
        "        ax.hist(all_points, bins=100)\n",
        "        ax.set_yscale('log')\n",
        "        ax.set_xlabel('Field amplitude', fontsize=12)\n",
        "        ax.set_ylabel('Number of data points (Log)', fontsize=12)\n",
        "        ax.axvline(x=cutoff, color='r', linestyle='-', label='Cutoff amplitude')\n",
        "\n",
        "        # Add text to the plot\n",
        "        textstr = f'Std. Dev. = {exprf_std:.2f}\\nMean = {exprf_mean:.2f}\\nCutoff = {cutoff:.2f} ({n_sigma} Std. Dev. from mean)'\n",
        "        ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=10,\n",
        "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "        ax.set_title('Random Field Statistics', fontsize=14)\n",
        "        ax.legend(loc='upper right')\n",
        "        ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "        # Save the plot with text\n",
        "        #plt.savefig(f'Statistic_info_Threshold_at_{cutoff}.pdf')\n",
        "        plt.show()\n",
        "\n",
        "        return fig, cutoff, exprf_std, exprf_mean"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NbhCNlvNTaQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1.12 GPU Cluster analysis\n",
        "\n",
        "class GPU_CLUST_ANALY:\n",
        "\n",
        "    def __init__(self, exprf, pixel, z_pixel):\n",
        "        self.pixel = pixel\n",
        "        self.z_pixel = z_pixel\n",
        "        self.exprf = exprf\n",
        "\n",
        "    def masking(self, cutoff):\n",
        "        # 5. Save mask and positions where amplitude exceed threshold\n",
        "        mask = cp.abs(self.exprf) > cutoff\n",
        "        masked_positions = cp.argwhere(mask)\n",
        "        # cp.save(f'mask_at_{cutoff:.1f}.npy', mask)\n",
        "        # cp.save(f'mask_positions_at_{cutoff:.1f}.npy', masked_positions)\n",
        "\n",
        "        return masked_positions\n",
        "\n",
        "    def dbscan(self, eps, min_sam, masked_positions):\n",
        "        dbscans = DBSCAN(eps=eps, min_samples=min_sam)\n",
        "        cluster_labels = dbscans.fit_predict(masked_positions)\n",
        "\n",
        "        return cluster_labels\n",
        "\n",
        "    def submanifolds(self, masked_positions, lx, ly, lz):\n",
        "        sub_manifolds_list={}\n",
        "        total_mass={}\n",
        "\n",
        "        for ii in range(masked_positions.shape[0]):\n",
        "            x, y, z = masked_positions[ii]\n",
        "            x_min, x_max = max(x- lx,0), min(x+ lx +1, self.pixel)\n",
        "            y_min, y_max = max(y- ly,0), min(y+ ly +1, self.pixel)\n",
        "            z_min, z_max = max(z- lz,0), min(z+ lz +1, self.z_pixel)\n",
        "\n",
        "            sub_exprf = self.exprf[x_min:x_max, y_min:y_max, z_min:z_max]\n",
        "            sub_manifolds_list[ii] = sub_exprf\n",
        "            total_mass[ii] = cp.sum(sub_exprf)\n",
        "\n",
        "        cp.save(f'sub_manifolds_list.npy', sub_manifolds_list )\n",
        "        cp.save(f'total_amplitude.npy', total_mass)\n",
        "\n",
        "        return sub_manifolds_list, total_mass\n",
        "\n",
        "        # @title 1.4 DBSCAN\n",
        "\n",
        "    def cluster_distances(self, masked_positions, labels):\n",
        "        cluster_centers = {}\n",
        "\n",
        "        # Find unique cluster labels (excluding noise -1)\n",
        "        unique_labels = set(labels) - {-1}\n",
        "\n",
        "        # Calculate cluster centers\n",
        "        for ii in set(unique_labels):\n",
        "            cluster_indices = cp.where(labels == ii)[0]\n",
        "            cluster_positions = masked_positions[cluster_indices]\n",
        "            cluster_center = cp.mean(cluster_positions, axis=0)\n",
        "            cluster_centers[ii] = cluster_center\n",
        "\n",
        "        # Calculate distances between cluster centers\n",
        "        distances = []\n",
        "        for aa in cluster_centers:\n",
        "            for bb in cluster_centers:\n",
        "                if aa != bb & bb > aa:\n",
        "                    distance = euclidean_distances([cluster_centers[aa]], [cluster_centers[bb]])\n",
        "                    distances.append((aa,bb, distance))\n",
        "\n",
        "        return distances\n",
        "\n",
        "\n",
        "    def cluster_distribution_3d(self, positions, labels):\n",
        "\n",
        "        all_cluster_position = {}\n",
        "        cluster_field_values={}\n",
        "        for ii in set(labels):\n",
        "            cluster_indices = cp.where(labels == ii)[0]\n",
        "            all_cluster_position[ii+1] = positions[cluster_indices]\n",
        "            cluster_field_values[ii+1] = self.exprf[all_cluster_position[ii+1][:,0],\n",
        "                                            all_cluster_position[ii+1][:,1],\n",
        "                                            all_cluster_position[ii+1][:,2]]\n",
        "\n",
        "        for ii in set(labels):\n",
        "            plt.hist(cluster_field_values[ii+1].flatten(), bins = 100, label=f'Cluster {ii}', alpha=0.3);\n",
        "            #plt.yscale('log')\n",
        "            plt.xlabel('Field amplitude')\n",
        "            plt.ylabel('Number of samples')\n",
        "            plt.title(f'Cluster Distribution')\n",
        "            plt.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
        "            plt.grid(True)\n",
        "\n",
        "        return cluster_field_values\n",
        "\n",
        "\n",
        "    def cluster_plot_3D(self, positions, labels):\n",
        "\n",
        "        fig = plt.figure(figsize=(5, 5))\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "        for ii in set(labels):\n",
        "            cluster_index = cp.where(labels == ii)[0]\n",
        "            cluster_positions = positions[cluster_index]\n",
        "\n",
        "            if ii == -1:\n",
        "                ax.scatter(-cluster_positions[:, 0], cluster_positions[:, 1], cluster_positions[:, 2],\n",
        "                        s=3, color='black', label='Anomaly')\n",
        "            else:\n",
        "                ax.scatter(-cluster_positions[:, 0], cluster_positions[:, 1], cluster_positions[:, 2],\n",
        "                        s=3, label=f'Cluster {ii}')\n",
        "\n",
        "        ax.set_xlabel('X', fontsize=10)\n",
        "        ax.set_ylabel('Y', fontsize=10)\n",
        "        ax.set_zlabel('Z', fontsize=10)\n",
        "        ax.set_title(f'Clustered 3D field config', fontsize=14)\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "873hLEGPTsFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Paramters\n",
        "pixel = 2**9\n",
        "z_pixel = pixel\n",
        "n_sigma = 25\n",
        "\n",
        "\n",
        "eps = 25\n",
        "min_sam = 5\n",
        "cluster_cutoff = 13\n",
        "\n",
        "\n",
        "default_l = 6 # This is the length from the center to the edge\n",
        "lx = default_l\n",
        "ly = default_l\n",
        "lz = default_l\n",
        "\n",
        "Nloops = 3000\n",
        "update_interval = max(1, Nloops // 20)"
      ],
      "metadata": {
        "id": "JmDlCGnwT8dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run simulation\n",
        "# Initialize an instance of RFSIM\n",
        "# rfsim = RFSIM(mean=0, std_dev=1, pixel=pixel, z_pixel=z_pixel, amplitude=1.0, k_power=3, lamb=1.0, n_sigma=n_sigma+1)\n",
        "rfsim = GPU_RFSIM(mean=0, std_dev=1, pixel=pixel, z_pixel=z_pixel, amplitude=1.0, k_power=3, lamb=1.0, n_sigma=n_sigma+1)\n",
        "\n",
        "for ii in tqdm(range(Nloops), desc=\"Processing\", miniters=update_interval):\n",
        "    # Generate a Gaussian random field\n",
        "    grf = rfsim.grf_64f()  # grf can be _32f or _64f\n",
        "    # Apply Gaussian to exponential transformation\n",
        "    exprf = rfsim.gaussian_to_exp(grf)\n",
        "    del grf\n",
        "    #gc.collect()\n",
        "\n",
        "\n",
        "    # Check if masked_positions is empty\n",
        "    # clust_analy = CLUST_ANALY(exprf=exprf,  pixel=pixel, z_pixel=z_pixel)\n",
        "    # Initialize an GPU Cluster Analysis\n",
        "    clust_analy = GPU_CLUST_ANALY(exprf=exprf,  pixel=pixel, z_pixel=z_pixel)\n",
        "    masked_positions = clust_analy.masking(cutoff = n_sigma+1)\n",
        "\n",
        "    if len(masked_positions) > 0:\n",
        "        new_folder = f\"simulated_field_{ii}\"\n",
        "        new_path = f\"simulated_field_{ii}/\"\n",
        "        os.makedirs(new_folder, exist_ok=True)\n",
        "\n",
        "        stat_fig, cutoff, exprf_std, exprf_mean = rfsim.statistic_overview(exprf)\n",
        "        stat_fig.savefig(  f'Statistic_{ii}_Threshold_at_{cutoff:.1f}.pdf')\n",
        "        cp.save(  f'exprf_{ii}.npy',exprf)\n",
        "        print(f'Found rare event at simulation {ii}')\n",
        "\n",
        "    del exprf\n",
        "    #gc.collect()"
      ],
      "metadata": {
        "id": "TWQANpFAUMAb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}