{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP/RrOayB6EjXDEeaG8dY4e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khchoi-physik/pbh_simulations/blob/main/GRFSimulator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP2jNduesw2K"
      },
      "outputs": [],
      "source": [
        "# @title Import packages\n",
        "\n",
        "from scipy.special import hankel2  # kurtosis -3 convention\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "import time as ti"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1.1 Random field simulations\n",
        "\n",
        "class grf_sim:\n",
        "\n",
        "    def __init__(self, pixel=2**9, mean=0, std_dev=1):\n",
        "        self.pixel = pixel\n",
        "        self.mean = mean\n",
        "        self.std_dev = std_dev\n",
        "        self.fft_white_noise, self.k_norm = self.grf_initialization()\n",
        "\n",
        "    def grf_initialization(self):\n",
        "        # Guassian white noise generation from GPU\n",
        "        white_noise = cp.random.normal(self.mean, self.std_dev, (self.pixel, self.pixel, self.pixel))\n",
        "\n",
        "        # FFT of Guassian white noise\n",
        "        fft_white_noise = cp.fft.fftn(white_noise).astype(cp.complex128)\n",
        "        del white_noise\n",
        "\n",
        "        # Generating FFT momentum\n",
        "        kx = cp.fft.fftfreq(self.pixel)*self.pixel\n",
        "        ky = cp.fft.fftfreq(self.pixel)*self.pixel\n",
        "        kz = cp.fft.fftfreq(self.pixel)*self.pixel\n",
        "\n",
        "        # Genearting FFT momentum 3D array\n",
        "        kx_grid, ky_grid, kz_grid = cp.meshgrid(kx, ky, kz)\n",
        "        # k_grid = np.meshgrid(kx, ky, kz)\n",
        "        del kx, ky, kz\n",
        "\n",
        "        # Norm of k\n",
        "        k_norm =  cp.sqrt( kx_grid**2 + ky_grid**2 + kz_grid**2 ) # k = sqrt( kx^2 + ky^2  + kz^2 )\n",
        "        k_norm[0,0,0] = cp.inf # Regularize divergence at k=0, for any power spectrum of spectral index less than.\n",
        "        del kx_grid, ky_grid, kz_grid\n",
        "\n",
        "        return fft_white_noise, k_norm\n",
        "\n",
        "    def generate_grf_desitter(self, time=1, amplitude=1/10, n_index=1.5):\n",
        "\n",
        "        k_norm = cp.asnumpy(self.k_norm)\n",
        "        amplitude = cp.asnumpy(amplitude)\n",
        "\n",
        "        fourier_amplitudes_sqrt =  np.sqrt(np.pi) * 0.5 *  amplitude   *  (time**(3/2)) * hankel2(n_index, time * ( (2 * np.pi/self.pixel)* k_norm) )\n",
        "        #(2 * np.pi / pixel) *\n",
        "        del k_norm\n",
        "\n",
        "        fourier_amplitudes_sqrt[0,0,0] = 0 # Regularize divergences at k_norm = 0.\n",
        "        fourier_amplitudes_sqrt = cp.asarray(fourier_amplitudes_sqrt).astype(cp.complex128)\n",
        "        fourier_amplitudes_sqrt = cp.abs(fourier_amplitudes_sqrt).astype(cp.complex128)\n",
        "\n",
        "        fourier_amplitudes_sqrt *= self.fft_white_noise\n",
        "\n",
        "        gaussian_random_field = cp.fft.ifftn(fourier_amplitudes_sqrt)\n",
        "        del fourier_amplitudes_sqrt\n",
        "\n",
        "        return gaussian_random_field.real\n",
        "\n",
        "\n",
        "    def run_simulation(self,  start_time, stop_time, time_step, run_id=0,  amplitude = 1/10, n_index=1.5, extra_time_range = [], save_grf_time = [], plot_bool = False ):\n",
        "\n",
        "        t0 = ti.time()\n",
        "\n",
        "        num_steps = int( (stop_time - start_time) / time_step) + 1\n",
        "\n",
        "        time_line = np.linspace(start_time, stop_time, num_steps)\n",
        "        time_line = np.concatenate( (time_line,  np.array(extra_time_range) ) )\n",
        "\n",
        "        statistics  = {'std': [], 'mean': [], 'skew': [], 'kurt': [], 'max_val': [], 'over_2std': []}\n",
        "\n",
        "        for time in time_line:\n",
        "\n",
        "            t1 = ti.time()\n",
        "            grf = self.generate_grf_desitter(time=time, amplitude=amplitude, n_index=n_index)\n",
        "            grf = grf.real\n",
        "\n",
        "            # Gather statistics\n",
        "            stat_fig, grf_std, grf_mean, grf_skew, grf_kurt = self.stats_overview(grf)\n",
        "\n",
        "            grf_abs_flatten = cp.abs(grf).flatten()\n",
        "            grf_max_val = cp.max(grf_abs_flatten).get()\n",
        "            samples_over_2std = grf_abs_flatten[grf_abs_flatten > (2 * grf_std)]\n",
        "            percent_over_2std = (samples_over_2std.size / grf_abs_flatten.size) * 100\n",
        "\n",
        "            for key, value in zip(statistics.keys(), [grf_std, grf_mean, grf_skew, grf_kurt, grf_max_val, percent_over_2std]):\n",
        "                statistics[key].append([time, value])\n",
        "\n",
        "            if run_id == 0 and plot_bool == True and round(time,4) in save_grf_time:\n",
        "                cp.save(f'grf_t={time:.4f}_pixel={self.pixel}.npy', grf)\n",
        "            #   plot_temperature_maps(grf, time, pixel, z_pos, grf_std, grf_mean, plot_bool, stat_fig, n_sigmas, vmin, vmax)\n",
        "\n",
        "                tf = ti.time() - t1\n",
        "                print(f't= {time:.4f}: Computational time is: {tf:.2f} seconds')\n",
        "                plt.close('all')\n",
        "\n",
        "        # Save statistics\n",
        "        self.save_statistics(statistics, run_id)\n",
        "\n",
        "        tf = ti.time() - t0\n",
        "        print(f'Run: {run_id+1}: Computational time for this runs is: {tf:.2f} seconds')\n",
        "        plt.close('all')\n",
        "\n",
        "\n",
        "    def stats_overview(self, grf):\n",
        "\n",
        "        all_points = cp.asnumpy(grf.flatten())\n",
        "        del grf\n",
        "\n",
        "        grf_std = np.std(all_points)\n",
        "        grf_mean = np.mean(all_points)\n",
        "        grf_skew = skew(all_points)\n",
        "        grf_kurt = kurtosis(all_points)\n",
        "\n",
        "        plt.hist(all_points, bins=256)\n",
        "\n",
        "        textstr = (f'Std. Dev. = {grf_std:.4f}\\n'\n",
        "                f'Mean = {grf_mean:.4f}\\n'\n",
        "                f'Skewness = {grf_skew:.4f}\\n'\n",
        "                f'Kurtosis = {grf_kurt:.4f}')\n",
        "\n",
        "        plt.gca().text(0.05, 0.95, textstr, transform=plt.gca().transAxes, fontsize=14,\n",
        "                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "\n",
        "        plt.title('Random Field Statistics', fontsize=16)\n",
        "        plt.xlabel('Field amplitude', fontsize=16)\n",
        "        plt.ylabel('Number of data points', fontsize=16)\n",
        "\n",
        "        return plt.gcf(), grf_std, grf_mean, grf_skew, grf_kurt\n",
        "\n",
        "\n",
        "    def save_statistics(self, statistics, run_id):\n",
        "        np.save(f'percent_over_2std_array_run_{run_id+1}.npy', np.array(statistics['over_2std']))\n",
        "        np.save(f'max_val_array_run_{run_id+1}.npy', np.array(statistics['max_val']) )\n",
        "        np.save(f'std_array_run_{run_id+1}.npy', np.array(statistics['std']))\n",
        "        np.save(f'mean_array_run_{run_id+1}.npy', np.array(statistics['mean']))\n",
        "        np.save(f'skew_array_run_{run_id+1}.npy', np.array(statistics['skew']))\n",
        "        np.save(f'kurt_array_run_{run_id+1}.npy', np.array(statistics['kurt']))"
      ],
      "metadata": {
        "id": "S1nye0DBsxr5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}